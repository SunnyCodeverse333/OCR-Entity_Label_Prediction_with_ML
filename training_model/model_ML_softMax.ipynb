{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "655d63ec-e67f-439f-a2e6-0d4a67c4bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7abf4cd7-ab11-468d-b658-e816af120ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_left_x</th>\n",
       "      <th>top_left_y</th>\n",
       "      <th>bottom_right_x</th>\n",
       "      <th>bottom_right_y</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215</td>\n",
       "      <td>4</td>\n",
       "      <td>227</td>\n",
       "      <td>21</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>308</td>\n",
       "      <td>21</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>311</td>\n",
       "      <td>3</td>\n",
       "      <td>349</td>\n",
       "      <td>20</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>352</td>\n",
       "      <td>3</td>\n",
       "      <td>401</td>\n",
       "      <td>20</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>404</td>\n",
       "      <td>3</td>\n",
       "      <td>457</td>\n",
       "      <td>21</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237611</th>\n",
       "      <td>365</td>\n",
       "      <td>1064</td>\n",
       "      <td>385</td>\n",
       "      <td>1079</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237612</th>\n",
       "      <td>388</td>\n",
       "      <td>1064</td>\n",
       "      <td>429</td>\n",
       "      <td>1079</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237613</th>\n",
       "      <td>451</td>\n",
       "      <td>1063</td>\n",
       "      <td>482</td>\n",
       "      <td>1078</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237614</th>\n",
       "      <td>485</td>\n",
       "      <td>1063</td>\n",
       "      <td>509</td>\n",
       "      <td>1078</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237615</th>\n",
       "      <td>511</td>\n",
       "      <td>1063</td>\n",
       "      <td>572</td>\n",
       "      <td>1078</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237616 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        top_left_x  top_left_y  bottom_right_x  bottom_right_y label_text\n",
       "0              215           4             227              21      OTHER\n",
       "1              235           3             308              21      OTHER\n",
       "2              311           3             349              20      OTHER\n",
       "3              352           3             401              20      OTHER\n",
       "4              404           3             457              21      OTHER\n",
       "...            ...         ...             ...             ...        ...\n",
       "237611         365        1064             385            1079      OTHER\n",
       "237612         388        1064             429            1079      OTHER\n",
       "237613         451        1063             482            1078      OTHER\n",
       "237614         485        1063             509            1078      OTHER\n",
       "237615         511        1063             572            1078      OTHER\n",
       "\n",
       "[237616 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Directory containing the dataset\n",
    "directory = r\"C:\\Users\\HP\\Downloads\\proj\\dataset\\train\\boxes_transcripts_labels\"\n",
    "\n",
    "# List of all files in the directory\n",
    "files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.tsv')]\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file and load the required columns\n",
    "for file in files:\n",
    "    # Load the file, assuming no header in the file\n",
    "    df = pd.read_csv(file, header=None, delimiter=\",\")  # Specify delimiter if it's a tab-separated file (.tsv)\n",
    "\n",
    "    # Select columns 2, 3, 4, 5 for features and column 7 for the textual labels\n",
    "    selected_columns = df.iloc[:, [2, 3, 4, 5, 7]]  # Adjusting indices to match the correct columns\n",
    "    dataframes.append(selected_columns)\n",
    "\n",
    "# Combine all files into a single dataframe\n",
    "combined_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "combined_data.columns = ['top_left_x', 'top_left_y', 'bottom_right_x', 'bottom_right_y', 'label_text']\n",
    "\n",
    "combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5b9650f-0815-4a10-9a68-10d4814c02e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "top_left_x         int64\n",
       "top_left_y         int64\n",
       "bottom_right_x     int64\n",
       "bottom_right_y     int64\n",
       "label_text        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dbcc53c-e17d-4e1f-9fe2-8143600d820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_left_x        0\n",
      "top_left_y        0\n",
      "bottom_right_x    0\n",
      "bottom_right_y    0\n",
      "label_text        0\n",
      "dtype: int64\n",
      "Label Mapping: {0: 'OTHER', 1: 'box16StateWagesTips', 2: 'box17StateIncomeTax', 3: 'box1WagesTipsAndOtherCompensations', 4: 'box2FederalIncomeTaxWithheld', 5: 'box3SocialSecurityWages', 6: 'box4SocialSecurityTaxWithheld', 7: 'einEmployerIdentificationNumber', 8: 'employeeName', 9: 'employerAddressCity', 10: 'employerAddressState', 11: 'employerAddressStreet_name', 12: 'employerAddressZip', 13: 'employerName', 14: 'ssnOfEmployee', 15: 'taxYear'}\n",
      "   top_left_x  top_left_y  bottom_right_x  bottom_right_y label_text  \\\n",
      "0         215           4             227              21      OTHER   \n",
      "1         235           3             308              21      OTHER   \n",
      "2         311           3             349              20      OTHER   \n",
      "3         352           3             401              20      OTHER   \n",
      "4         404           3             457              21      OTHER   \n",
      "\n",
      "   class_label  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(combined_data.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values, if any\n",
    "combined_data = combined_data.dropna()\n",
    "\n",
    "# Convert class labels (label_text) to numeric using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "combined_data['class_label'] = label_encoder.fit_transform(combined_data['label_text'])\n",
    "\n",
    "# Print the label mapping\n",
    "print(\"Label Mapping:\", dict(enumerate(label_encoder.classes_)))\n",
    "\n",
    "# Optionally, print the first few rows of the data to confirm\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4130c416-b7f1-41ac-9d16-e0d9a528fde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (190092, 4)\n",
      "Testing set shape: (47524, 4)\n"
     ]
    }
   ],
   "source": [
    "# Features: Columns 3, 4, 5, 6\n",
    "X = combined_data[['top_left_x', 'top_left_y', 'bottom_right_x', 'bottom_right_y']]\n",
    "\n",
    "# Labels: Column 'class_label'\n",
    "y = combined_data['class_label']\n",
    "\n",
    "# Split into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03fe7635-50e4-4ae6-9716-49593e672d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_left_x         int64\n",
      "top_left_y         int64\n",
      "bottom_right_x     int64\n",
      "bottom_right_y     int64\n",
      "label_text        object\n",
      "class_label        int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(combined_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dce860ac-20ac-41ec-a325-e0528f86c3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  21   20   23 ... 2514 2518 2554]\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['bottom_right_y'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b48afe55-2c53-4a7a-93a0-dab19b4d6369",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 2.6430 - val_accuracy: 0.9372 - val_loss: 0.3523\n",
      "Epoch 2/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.3551 - val_accuracy: 0.9361 - val_loss: 0.3790\n",
      "Epoch 3/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.9361 - loss: 0.3372 - val_accuracy: 0.9375 - val_loss: 0.3286\n",
      "Epoch 4/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.9366 - loss: 0.3301 - val_accuracy: 0.9371 - val_loss: 0.3244\n",
      "Epoch 5/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.9365 - loss: 0.3286 - val_accuracy: 0.9367 - val_loss: 0.3321\n",
      "Epoch 6/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.3249 - val_accuracy: 0.9381 - val_loss: 0.3173\n",
      "Epoch 7/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.9376 - loss: 0.3181 - val_accuracy: 0.9378 - val_loss: 0.3251\n",
      "Epoch 8/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.3147 - val_accuracy: 0.9381 - val_loss: 0.3240\n",
      "Epoch 9/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9391 - loss: 0.3101 - val_accuracy: 0.9368 - val_loss: 0.3194\n",
      "Epoch 10/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9366 - loss: 0.3214 - val_accuracy: 0.9380 - val_loss: 0.3123\n",
      "Epoch 11/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.9368 - loss: 0.3174 - val_accuracy: 0.9369 - val_loss: 0.3232\n",
      "Epoch 12/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.3119 - val_accuracy: 0.9377 - val_loss: 0.3152\n",
      "Epoch 13/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.3134 - val_accuracy: 0.9379 - val_loss: 0.3075\n",
      "Epoch 14/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9382 - loss: 0.3123 - val_accuracy: 0.9379 - val_loss: 0.3052\n",
      "Epoch 15/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.9380 - loss: 0.3144 - val_accuracy: 0.9376 - val_loss: 0.3068\n",
      "Epoch 16/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9383 - loss: 0.3101 - val_accuracy: 0.9377 - val_loss: 0.3085\n",
      "Epoch 17/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9386 - loss: 0.3079 - val_accuracy: 0.9376 - val_loss: 0.3292\n",
      "Epoch 18/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.3099 - val_accuracy: 0.9376 - val_loss: 0.3117\n",
      "Epoch 19/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.9376 - loss: 0.3128 - val_accuracy: 0.9383 - val_loss: 0.3071\n",
      "Epoch 20/20\n",
      "\u001b[1m5347/5347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - accuracy: 0.9396 - loss: 0.3023 - val_accuracy: 0.9380 - val_loss: 0.3211\n",
      "\u001b[1m1486/1486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.3215\n",
      "Test accuracy: 93.86%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming y_train is already encoded using LabelEncoder, let's one-hot encode the labels\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_dim=X_train.shape[1]),  # First hidden layer\n",
    "    Dense(32, activation='relu'),  # Second hidden layer\n",
    "    Dense(y_train_encoded.shape[1], activation='softmax')  # Output layer with softmax\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_encoded, epochs=20, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211200a-4899-458e-9aa2-ba3e75b4e89f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## testing the model using test_val_ans datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e353905d-0db2-4f51-924e-3caf780c790b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_left_x        0\n",
      "top_left_y        0\n",
      "bottom_right_x    0\n",
      "bottom_right_y    0\n",
      "label_text        0\n",
      "dtype: int64\n",
      "\u001b[1m2515/2515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\n",
      "Accuracy on the test set: 93.60%\n",
      "Predictions for the test set (first few):\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n",
      "Predicted Labels for the test set (first few):\n",
      "['OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER'\n",
      " 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'ssnOfEmployee' 'OTHER' 'OTHER'\n",
      " 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER'\n",
      " 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER'\n",
      " 'OTHER' 'OTHER' 'einEmployerIdentificationNumber' 'OTHER' 'OTHER' 'OTHER'\n",
      " 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER' 'OTHER']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Directory containing the dataset with answers of the test\n",
    "directory = r\"C:\\Users\\HP\\Downloads\\proj\\dataset\\val_w_ann\\boxes_transcripts_labels\"\n",
    "\n",
    "# List of all files in the directory\n",
    "files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.tsv')]\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file and load the required columns (features and labels)\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, header=None, delimiter=\",\")  # Adjust delimiter for .tsv files\n",
    "    selected_columns = df.iloc[:, [2, 3, 4, 5, 7]]  # Columns with features and label\n",
    "    dataframes.append(selected_columns)\n",
    "\n",
    "# Combine all files into a single DataFrame\n",
    "test_combined_data_Answers = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "test_combined_data_Answers.columns = ['top_left_x', 'top_left_y', 'bottom_right_x', 'bottom_right_y', 'label_text']\n",
    "\n",
    "# Check for missing values\n",
    "print(test_combined_data_Answers.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values, if any\n",
    "test_combined_data_Answers = test_combined_data_Answers.dropna()\n",
    "\n",
    "# Convert class labels (label_text) to numeric using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "test_combined_data_Answers['class_label'] = label_encoder.fit_transform(test_combined_data_Answers['label_text'])\n",
    "\n",
    "# Now, split the data into X_test (features) and y_test (labels)\n",
    "X_test = test_combined_data_Answers[['top_left_x', 'top_left_y', 'bottom_right_x', 'bottom_right_y']]\n",
    "y_test = test_combined_data_Answers['class_label']\n",
    "\n",
    "\n",
    "# Use the model to predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Since softmax returns probabilities, we need to get the index of the max value (the predicted class)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)\n",
    "\n",
    "# Evaluate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Optionally, print the first few predictions\n",
    "print(\"Predictions for the test set (first few):\")\n",
    "print(y_pred_classes[:50])\n",
    "\n",
    "# If you want to decode the predicted classes back to their original labels\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
    "print(\"Predicted Labels for the test set (first few):\")\n",
    "print(y_pred_labels[:50])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
