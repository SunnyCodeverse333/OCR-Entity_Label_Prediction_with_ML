{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b465fc6-0fb3-4272-b375-00a65125d4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 942us/step - loss: 3.7904\n",
      "Epoch 2/10\n",
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 933us/step - loss: 0.3625\n",
      "Epoch 3/10\n",
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 923us/step - loss: 0.2890\n",
      "Epoch 4/10\n",
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 936us/step - loss: 0.2789\n",
      "Epoch 5/10\n",
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 938us/step - loss: 0.2691\n",
      "Epoch 6/10\n",
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 937us/step - loss: 0.2695\n",
      "Epoch 7/10\n",
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 927us/step - loss: 0.2673\n",
      "Epoch 8/10\n",
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 936us/step - loss: 0.2647\n",
      "Epoch 9/10\n",
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 935us/step - loss: 0.2652\n",
      "Epoch 10/10\n",
      "\u001b[1m7426/7426\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 938us/step - loss: 0.2630\n",
      "\u001b[1m2515/2515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 587us/step\n",
      "Metrics with indices saved to metrics_with_indices.tsv:\n",
      "                                 Field  Precision    Recall  F1-Score  \\\n",
      "0                                OTHER   0.940783  0.998590  0.968825   \n",
      "1                  box16StateWagesTips   0.000000  0.000000  0.000000   \n",
      "2                  box17StateIncomeTax   0.000000  0.000000  0.000000   \n",
      "3   box1WagesTipsAndOtherCompensations   0.000000  0.000000  0.000000   \n",
      "4         box2FederalIncomeTaxWithheld   0.000000  0.000000  0.000000   \n",
      "5              box3SocialSecurityWages   0.000000  0.000000  0.000000   \n",
      "6        box4SocialSecurityTaxWithheld   0.000000  0.000000  0.000000   \n",
      "7      einEmployerIdentificationNumber   0.903226  0.287179  0.435798   \n",
      "8                         employeeName   0.000000  0.000000  0.000000   \n",
      "9                  employerAddressCity   0.339623  0.059016  0.100559   \n",
      "10                employerAddressState   0.000000  0.000000  0.000000   \n",
      "11          employerAddressStreet_name   0.500000  0.016539  0.032020   \n",
      "12                  employerAddressZip   0.527559  0.336683  0.411043   \n",
      "13                        employerName   0.488000  0.087644  0.148599   \n",
      "14                       ssnOfEmployee   0.868421  0.381503  0.530120   \n",
      "15                             taxYear   0.607477  0.375723  0.464286   \n",
      "\n",
      "    start_index  end_index  \n",
      "0            33         33  \n",
      "1            35         44  \n",
      "2            46         51  \n",
      "3            53         60  \n",
      "4            62         67  \n",
      "5           115        119  \n",
      "6           121        129  \n",
      "7           131        132  \n",
      "8           134        134  \n",
      "9           136        139  \n",
      "10          141        145  \n",
      "11          147        149  \n",
      "12          151        153  \n",
      "13          155        161  \n",
      "14          210        220  \n",
      "15          249        251  \n",
      "Accuracy on the validation set: 93.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Directory containing the training dataset\n",
    "train_directory = r\"C:\\Users\\HP\\Downloads\\proj\\dataset\\train\\boxes_transcripts_labels\"\n",
    "\n",
    "# List of all files in the training directory\n",
    "train_files = [os.path.join(train_directory, f) for f in os.listdir(train_directory) if f.endswith('.tsv')]\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "train_dataframes = []\n",
    "\n",
    "# Loop through each file in the training set\n",
    "for file in train_files:\n",
    "    df = pd.read_csv(file, header=None, delimiter=\",\")  # Adjust delimiter for .tsv files\n",
    "    selected_columns = df.iloc[:, [0, 1, 2, 3, 4, 5, 7]]  # Columns with features and label\n",
    "    train_dataframes.append(selected_columns)\n",
    "\n",
    "# Combine all training files into a single DataFrame\n",
    "combined_train_data = pd.concat(train_dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "combined_train_data.columns = ['start_index', 'end_index', 'top_left_x', 'top_left_y', 'bottom_right_x', 'bottom_right_y', 'label_text']\n",
    "\n",
    "# Drop rows with missing values\n",
    "combined_train_data = combined_train_data.dropna()\n",
    "\n",
    "# Convert class labels (label_text) to numeric using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "combined_train_data['class_label'] = label_encoder.fit_transform(combined_train_data['label_text'])\n",
    "\n",
    "# Features and Labels for training\n",
    "X_train = combined_train_data[['top_left_x', 'top_left_y', 'bottom_right_x', 'bottom_right_y']]\n",
    "y_train = combined_train_data['class_label']\n",
    "\n",
    "# One-hot encode the labels for neural network\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "\n",
    "# Build the neural network model\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(y_train_encoded.shape[1], activation='softmax')  # Output layer size matches number of classes\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_encoded, epochs=10)\n",
    "\n",
    "# Directory containing the validation dataset\n",
    "val_directory = r\"C:\\Users\\HP\\Downloads\\proj\\dataset\\val_w_ann\\boxes_transcripts_labels\"\n",
    "\n",
    "# List of all files in the validation directory\n",
    "val_files = [os.path.join(val_directory, f) for f in os.listdir(val_directory) if f.endswith('.tsv')]\n",
    "\n",
    "# Initialize an empty list to store the validation data\n",
    "val_dataframes = []\n",
    "\n",
    "# Loop through each file in the validation set\n",
    "for file in val_files:\n",
    "    df = pd.read_csv(file, header=None, delimiter=\",\")  # Adjust delimiter for .tsv files\n",
    "    selected_columns = df.iloc[:, [0, 1, 2, 3, 4, 5, 7]]  # Columns with features and label\n",
    "    val_dataframes.append(selected_columns)\n",
    "\n",
    "# Combine all validation files into a single DataFrame\n",
    "combined_val_data = pd.concat(val_dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "combined_val_data.columns = ['start_index', 'end_index', 'top_left_x', 'top_left_y', 'bottom_right_x', 'bottom_right_y', 'label_text']\n",
    "\n",
    "# Drop rows with missing values\n",
    "combined_val_data = combined_val_data.dropna()\n",
    "\n",
    "# Convert class labels (label_text) to numeric using LabelEncoder\n",
    "combined_val_data['class_label'] = label_encoder.fit_transform(combined_val_data['label_text'])\n",
    "\n",
    "# Features and Labels for validation\n",
    "X_val = combined_val_data[['top_left_x', 'top_left_y', 'bottom_right_x', 'bottom_right_y']]\n",
    "y_val = combined_val_data['class_label']\n",
    "\n",
    "# Use the model to predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels (argmax)\n",
    "y_pred_classes = y_pred.argmax(axis=-1)\n",
    "\n",
    "# Calculate precision, recall, and F1 score for each class\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    y_val, y_pred_classes, average=None  # Class-wise metrics\n",
    ")\n",
    "\n",
    "# Decode the class labels back to their original entity names\n",
    "class_names = label_encoder.inverse_transform(range(len(label_encoder.classes_)))\n",
    "\n",
    "# Prepare the metrics data\n",
    "metrics = []\n",
    "for i, class_name in enumerate(class_names):\n",
    "    metrics.append([class_name, precision[i], recall[i], f1[i]])\n",
    "\n",
    "# Convert the metrics into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics, columns=['Field', 'Precision', 'Recall', 'F1-Score'])\n",
    "\n",
    "# Now ensure that the 'start_index' and 'end_index' are aligned correctly to the rows\n",
    "metrics_df['start_index'] = combined_val_data['start_index'].values[:len(metrics_df)]\n",
    "metrics_df['end_index'] = combined_val_data['end_index'].values[:len(metrics_df)]\n",
    "\n",
    "# Save the metrics to a .tsv file\n",
    "metrics_df.to_csv('metrics_with_indices.tsv', sep='\\t', index=False)\n",
    "\n",
    "# Print the metrics to verify\n",
    "print(\"Metrics with indices saved to metrics_with_indices.tsv:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Evaluate model accuracy on validation set\n",
    "accuracy = accuracy_score(y_val, y_pred_classes)\n",
    "print(f\"Accuracy on the validation set: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
